{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con=sqlite3.connect(\"/Users/xiaoweichen/Kaggle/ClintonEmails/data/database.sqlite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_sql_query(\"SELECT * FROM Emails\",con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter set contains all stop words\n",
    "filter_set=set(stopwords.words(\"english\"))\n",
    "# feature set contains all single words (token) that are not stop words\n",
    "feature_set=set()\n",
    "# Go through all subjects\n",
    "for subject in df.MetadataSubject.unique():\n",
    "    tokens=nltk.word_tokenize(subject)\n",
    "    tokens=[token for token in tokens if token not in filter_set]\n",
    "    for token in tokens:\n",
    "        feature_set.add(token)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                  WOW\n",
       "1    H: LATEST: HOW SYRIA IS AIDING QADDAFI AND MOR...\n",
       "2                                        CHRIS STEVENS\n",
       "Name: MetadataSubject, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['MetadataSubject'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emails=[]\n",
    "persons=[]\n",
    "from_=[]\n",
    "to_=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for subject in df.MetadataSubject.unique():\n",
    "    tokens=nltk.word_tokenize(subject)\n",
    "    # Retrieve the sender info for the specific subject\n",
    "    # and remove all semicolon from the sender info\n",
    "    from_=[person.replace(\";\",\"\") for person in df[df.MetadataSubject == subject].MetadataFrom.values if person != '']\n",
    "    # Retrieve the receiver info for the specific subject\n",
    "    # and remove all semicolon from the string of \"To:\"\n",
    "    to_=[person.replace(\";\",\"\") for person in df[df.MetadataSubject == subject].MetadataTo.values if person !='']\n",
    "    # Note the use of set: remove duplicate elements\n",
    "    from_.append(set(from_))\n",
    "    to_.append(set(to_))\n",
    "    # All contacts: sender and receiver\n",
    "    persons.append(from_+to_)\n",
    "    \n",
    "    tokens=set([token for token in tokens if token not in filter_set])\n",
    "    email=[1 if feature in tokens else 0 for feature in feature_set]\n",
    "    emails.append(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k=5\n",
    "X=np.matrix(emails)\n",
    "km=MiniBatchKMeans(n_clusters=k).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top_k_tags_per_cluster={}\n",
    "for cluster,center in enumerate(km.cluster_centers_):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
